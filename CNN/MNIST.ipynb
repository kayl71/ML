{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfd9393b-33a5-4da8-8f2f-e57700e3dd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.5.1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# Проверка версии PyTorch\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "\n",
    "\n",
    "# SGD 100 epoch -> 84.84%\n",
    "# Adam 100 epcoch -> 93.44%\n",
    "# Adam + OneCycleLR 100 epoch -> 89.86% (too slow!)\n",
    "# Adam + high lw (0.01) 100 epoch -> 97.76% !!!!!!!!!!!\n",
    "# Adam + very high lw (0.1) 100 epoch -> 93.76% (not stability in start)\n",
    "# Adam + high lw (0.01) + StepLR (step_size=100) 200 epoch -> 97.97% (need stop in 120 epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a276cb9-9b27-4cac-9450-e377b1790ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n",
    "\n",
    "# print(path)\n",
    "path = '/home/kayl/.cache/kagglehub/datasets/hojjatk/mnist-dataset/versions/1'\n",
    "\n",
    "#\n",
    "# This is a sample Notebook to demonstrate how to read \"MNIST Dataset\"\n",
    "#\n",
    "import struct\n",
    "from array import array\n",
    "from os.path  import join\n",
    "\n",
    "#\n",
    "# MNIST Data Loader Class\n",
    "#\n",
    "# path = kagglehub.dataset_download(\"hojjatk/mnist-dataset\")\n",
    "class MnistDataloader:\n",
    "    def __init__(self, training_images_filepath, training_labels_filepath,\n",
    "                 test_images_filepath, test_labels_filepath):\n",
    "        self.training_images_filepath = training_images_filepath\n",
    "        self.training_labels_filepath = training_labels_filepath\n",
    "        self.test_images_filepath = test_images_filepath\n",
    "        self.test_labels_filepath = test_labels_filepath\n",
    "\n",
    "    def read_images_labels(self, images_filepath, labels_filepath):\n",
    "        with open(labels_filepath, 'rb') as file:\n",
    "            magic, size = struct.unpack(\">II\", file.read(8))\n",
    "            if magic != 2049:\n",
    "                raise ValueError('Magic number mismatch, expected 2049, got {}'.format(magic))\n",
    "            labels = np.array(array(\"B\", file.read()))\n",
    "\n",
    "        with open(images_filepath, 'rb') as file:\n",
    "            magic, size, rows, cols = struct.unpack(\">IIII\", file.read(16))\n",
    "            if magic != 2051:\n",
    "                raise ValueError('Magic number mismatch, expected 2051, got {}'.format(magic))\n",
    "            image_data = np.array(array(\"B\", file.read()))\n",
    "        images = image_data.reshape(size, rows, cols)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_data(self):\n",
    "        x_train, y_train = self.read_images_labels(self.training_images_filepath, self.training_labels_filepath)\n",
    "        x_test, y_test = self.read_images_labels(self.test_images_filepath, self.test_labels_filepath)\n",
    "        return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1a1f70-1f33-4332-86da-01b2ebb52dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Verify Reading Dataset via MnistDataloader class\n",
    "#\n",
    "%matplotlib inline\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#\n",
    "# Set file paths based on added MNIST Datasets\n",
    "#\n",
    "input_path = path\n",
    "training_images_filepath = join(input_path, 'train-images-idx3-ubyte/train-images-idx3-ubyte')\n",
    "training_labels_filepath = join(input_path, 'train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n",
    "test_images_filepath = join(input_path, 't10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\n",
    "test_labels_filepath = join(input_path, 't10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')\n",
    "\n",
    "mnist_dataloader = MnistDataloader(training_images_filepath, training_labels_filepath, test_images_filepath, test_labels_filepath)\n",
    "(x_train, y_train), (x_test, y_test) = mnist_dataloader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29a272bc-4073-45c0-9d68-2fe8ee527b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_train(index):\n",
    "    if index >= 0 and index < len(x_train):\n",
    "        plt.imshow(x_train[index], cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "    else:\n",
    "        raise ValueError(f'incorrect index: {index}, max {len(x_train)}')\n",
    "def show_image_test(index):\n",
    "    if index >= 0 and index < len(x_test):\n",
    "        plt.imshow(x_test[index], cmap=plt.cm.gray)\n",
    "        plt.show()\n",
    "    else:\n",
    "        raise ValueError(f'incorrect index: {index}, max {len(x_test)}')\n",
    "\n",
    "class Net1hidden(nn.Module):\n",
    "    def __init__(self, L_input, L_hidden, L_output):\n",
    "        super(Net1hidden, self).__init__()\n",
    "        self.fc1 = nn.Linear(L_input, L_hidden)\n",
    "        self.fc2 = nn.Linear(L_hidden, L_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "\n",
    "        x = x.view(-1, 64*7*7)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class CNN_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64*7*7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be602019-b883-4741-b2ea-d59661b1f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For New1hidden\n",
    "x_train_line = np.array([x_train[i].reshape(28*28) for i in range(len(x_train))])\n",
    "X_train = torch.tensor(x_train_line / 255, dtype=torch.float32)\n",
    "Y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "x_test_line = np.array([x_test[i].reshape(28*28) for i in range(len(x_test))])\n",
    "X_test = torch.tensor(x_test_line / 255, dtype=torch.float32)\n",
    "Y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e53d95fc-a769-493c-9847-b90ff01b509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # For CNN\n",
    "# X_train = torch.tensor(x_train/255, dtype=torch.float32).unsqueeze(1)\n",
    "# Y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "# X_test = torch.tensor(x_test/255, dtype=torch.float32).unsqueeze(1)\n",
    "# Y_test = torch.tensor(y_test, dtype=torch.int64)\n",
    "\n",
    "# train_dataset = TensorDataset(X_train, Y_train)\n",
    "# test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "# train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a2a152-ef73-4aa7-8f1e-53d83ead1ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = CNN_2()\n",
    "# criterion = nn.CrossEntropyLoss()  # Функция потерь для классификации\n",
    "# # optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "# optimizer = optim.Adam(\n",
    "#     model.parameters(), \n",
    "#     lr = 0.001, \n",
    "#     betas = (0.9, 0.999), \n",
    "#     eps=1e-8,\n",
    "#     weight_decay=0.0)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ca7237-2c87-4256-9f56-8ac77399a068",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 800\n",
    "model = Net1hidden(28*28, L, 10)\n",
    "criterion = nn.CrossEntropyLoss()  # Функция потерь для классификации\n",
    "# optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = 0.001, \n",
    "    betas = (0.9, 0.999), \n",
    "    eps=1e-8,\n",
    "    weight_decay=0.0)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, Y_train)\n",
    "test_dataset = TensorDataset(X_test, Y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ff7da56-7e30-406b-aad8-8c1d7dbc9a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()  \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        test_loss /= len(test_loader.dataset)\n",
    "        accuracy = 100. * correct / len(test_loader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({accuracy:.2f}%)')\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5443fbb-8828-4720-a41a-f99d9e44b5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 0.0001, Accuracy: 9669/10000 (96.69%)\n",
      "Time: 4 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9701/10000 (97.01%)\n",
      "Time: 7 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9783/10000 (97.83%)\n",
      "Time: 11 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
      "Time: 15 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9798/10000 (97.98%)\n",
      "Time: 19 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9799/10000 (97.99%)\n",
      "Time: 23 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9823/10000 (98.23%)\n",
      "Time: 27 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9821/10000 (98.21%)\n",
      "Time: 31 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9807/10000 (98.07%)\n",
      "Time: 35 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9813/10000 (98.13%)\n",
      "Time: 39 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9815/10000 (98.15%)\n",
      "Time: 43 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9835/10000 (98.35%)\n",
      "Time: 47 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9829/10000 (98.29%)\n",
      "Time: 51 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9831/10000 (98.31%)\n",
      "Time: 55 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9781/10000 (97.81%)\n",
      "Time: 58 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9822/10000 (98.22%)\n",
      "Time: 62 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9832/10000 (98.32%)\n",
      "Time: 67 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9836/10000 (98.36%)\n",
      "Time: 71 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9850/10000 (98.50%)\n",
      "Time: 75 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9826/10000 (98.26%)\n",
      "Time: 79 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9842/10000 (98.42%)\n",
      "Time: 82 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9848/10000 (98.48%)\n",
      "Time: 87 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9850/10000 (98.50%)\n",
      "Time: 91 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9851/10000 (98.51%)\n",
      "Time: 94 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9851/10000 (98.51%)\n",
      "Time: 98 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9852/10000 (98.52%)\n",
      "Time: 103 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9851/10000 (98.51%)\n",
      "Time: 107 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 112 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 116 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 120 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9855/10000 (98.55%)\n",
      "Time: 125 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9860/10000 (98.60%)\n",
      "Time: 129 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9855/10000 (98.55%)\n",
      "Time: 133 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 137 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 141 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9851/10000 (98.51%)\n",
      "Time: 145 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9852/10000 (98.52%)\n",
      "Time: 149 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9853/10000 (98.53%)\n",
      "Time: 153 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 157 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 161 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9855/10000 (98.55%)\n",
      "Time: 165 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 169 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9855/10000 (98.55%)\n",
      "Time: 174 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 178 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 182 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 187 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9855/10000 (98.55%)\n",
      "Time: 191 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 195 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 199 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 204 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 208 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9854/10000 (98.54%)\n",
      "Time: 212 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 217 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 221 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 226 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 231 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 235 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9856/10000 (98.56%)\n",
      "Time: 240 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 245 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 249 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 254 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 259 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 263 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 268 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 273 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 278 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 283 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 289 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 294 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9858/10000 (98.58%)\n",
      "Time: 299 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 304 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 308 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 314 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 319 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 324 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 329 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 334 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 339 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 344 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 349 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 354 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 359 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 365 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 370 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 375 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 380 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 385 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 390 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 395 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 401 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 406 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 411 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 416 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 421 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 426 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 431 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 437 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 441 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 447 seconds\n",
      "Test set: Average loss: 0.0001, Accuracy: 9857/10000 (98.57%)\n",
      "Time: 452 seconds\n"
     ]
    }
   ],
   "source": [
    "epoch = 100\n",
    "accuracies = []\n",
    "\n",
    "start_time = time.time()\n",
    "for epoch in range(1, epoch+1):\n",
    "    train(epoch)\n",
    "    acc = test()\n",
    "    accuracies.append(acc)\n",
    "    scheduler.step()\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f'Time: {round(elapsed_time)} seconds')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "141d736a-35a0-4dec-8cec-af19e0e8645f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (20,) and (10,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracies\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/matplotlib/pyplot.py:3829\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3821\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3827\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3828\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3829\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3833\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (10,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1, epoch+1), accuracies)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('MNIST')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc337f4f-d77a-420a-930f-5a3a8f85000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"model_nn_adam.pth\"\n",
    "torch.save({\n",
    "    'model_state_dict' : model.state_dict(),\n",
    "    'optimizer_state_dict' : optimizer.state_dict(),\n",
    "    'epoch' : 120,\n",
    "    'loss' : loss,\n",
    "}, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b787dba8-155b-4c78-888c-181aff31c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8630/2728205505.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net1hidden(\n",
       "  (fc1): Linear(in_features=784, out_features=800, bias=True)\n",
       "  (fc2): Linear(in_features=800, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"model_nn_adam.pth\"\n",
    "checkpoint = torch.load(PATH)\n",
    "_model = Net1hidden(28*28, 800, 10)\n",
    "_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e6926ac-e9ac-436a-aaa7-f5b8fb8194f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 98.00%\n"
     ]
    }
   ],
   "source": [
    "_test, predicted_test = torch.max(_model(X_test), 1)  # Выбираем класс с наибольшим значением\n",
    "correct_test = (predicted_test == Y_test).sum().item()\n",
    "total_test = Y_test.size(0)\n",
    "accuracy_test = correct_test / total_test\n",
    "print(f'Accuracy on test set: {accuracy_test * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3b8b83-110c-43bc-8512-0e8f379d2e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    \n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model.forward(X_train)\n",
    "    loss = criterion(outputs, Y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs_test = model(X_test)\n",
    "        outputs_train = model(X_train)\n",
    "        _test, predicted_test = torch.max(outputs_test, 1)  # Выбираем класс с наибольшим значением\n",
    "        _train, predicted_train = torch.max(outputs_train, 1)  # Выбираем класс с наибольшим значением\n",
    "    \n",
    "        # Сравниваем предсказания с истинными метками\n",
    "        correct_test = (predicted_test == Y_test).sum().item()\n",
    "        total_test = Y_test.size(0)\n",
    "        correct_train = (predicted_train == Y_train).sum().item()\n",
    "        total_train = Y_train.size(0)\n",
    "        # Вычисляем точность\n",
    "        accuracy_test = correct_test / total_test\n",
    "        accuracy_train = correct_train / total_train\n",
    "        arr_y_forGraph_test.append(accuracy_test)\n",
    "        arr_y_forGraph_train.append(accuracy_train)\n",
    "        print(f'{i} (epoch) Loss: {loss.item():.4f}, Accuracy on test set: {accuracy_test * 100:.2f}%', f'Accuracy on train set: {accuracy_train * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e13f3-ae1d-4b63-8853-2469d3d3c2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x*100 for x in arr_y_forGraph_test], label='test')\n",
    "plt.plot([x*100 for x in arr_y_forGraph_train], label='train')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch, num')\n",
    "plt.ylabel('Accuracy, %')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6ae7be-d3f6-4cc8-8402-58dffd4d9a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6e8d1cd7-f488-4b1d-9dc6-3ecdc347b679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1eedd7bb-0c38-45e2-97f4-69ac4ccb6fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 0\n",
    "L = 800\n",
    "X_train = torch.tensor(x_train_line / 255, dtype=torch.float32)\n",
    "Y_train = torch.tensor(y_train, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d123f52-0ec5-4489-9cc4-3eae44ca67e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.9138\n",
      "Epoch [20/100], Loss: 0.7001\n"
     ]
    }
   ],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self, L_input, L_hidden, L_output):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(L_input, L_hidden)\n",
    "        self.fc2 = nn.Linear(L_hidden, L_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleNet(28*28, L, 10)\n",
    "criterion = nn.CrossEntropyLoss()  # Функция потерь для классификации\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(100):  # 100 эпох\n",
    "    optimizer.zero_grad()  # Обнуляем градиенты\n",
    "    outputs = model(X_train)  # Прямой проход\n",
    "    loss = criterion(outputs, Y_train)  # Вычисляем потери\n",
    "    loss.backward()  # Обратный проход (вычисление градиентов)\n",
    "    optimizer.step()  # Обновление параметров\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8bb23c2c-9f41-42ea-b948-8a0c3648caa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_line = np.array([x_test[i].reshape(28*28) for i in range(len(x_test))])\n",
    "X_test = torch.tensor(x_test_line / 255, dtype=torch.float32)\n",
    "Y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4a60e527-e3f7-4fb3-93db-4f4ce8a64d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 87.70%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test)\n",
    "    _, predicted = torch.max(outputs, 1)  # Выбираем класс с наибольшим значением\n",
    "\n",
    "    # Сравниваем предсказания с истинными метками\n",
    "    correct = (predicted == Y_test).sum().item()\n",
    "    total = Y_test.size(0)\n",
    "\n",
    "    # Вычисляем точность\n",
    "    accuracy = correct / total\n",
    "    print(f'Accuracy on test set: {accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d4c525-d60b-4fbe-b35a-8c1727004e12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
